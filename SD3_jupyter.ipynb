{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/SD3-jupyter/blob/main/SD3_jupyter.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone -b totoro2 https://github.com/camenduru/ComfyUI /content/TotoroUI\n",
        "%cd /content/TotoroUI\n",
        "\n",
        "!pip install -q torchsde einops diffusers accelerate xformers==0.0.26.post1\n",
        "!apt -y install -qq aria2\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/adamo1139/stable-diffusion-3-medium-ungated/resolve/main/sd3_medium_incl_clips_t5xxlfp8.safetensors -d /content/TotoroUI/model -o sd3_medium_incl_clips_t5xxlfp8.safetensors\n",
        "\n",
        "import torch\n",
        "import random\n",
        "import node_helpers\n",
        "from totoro.sd import load_checkpoint_guess_config\n",
        "import nodes\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "with torch.inference_mode():\n",
        "    model_patcher, clip, vae, clipvision = load_checkpoint_guess_config(\"/content/TotoroUI/model/sd3_medium_incl_clips_t5xxlfp8.safetensors\", output_vae=True, output_clip=True, embedding_directory=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def zero_out(conditioning):\n",
        "        c = []\n",
        "        for t in conditioning:\n",
        "            d = t[1].copy()\n",
        "            if \"pooled_output\" in d:\n",
        "                d[\"pooled_output\"] = torch.zeros_like(d[\"pooled_output\"])\n",
        "            n = [torch.zeros_like(t[0]), d]\n",
        "            c.append(n)\n",
        "        return (c, )\n",
        "\n",
        "with torch.inference_mode():\n",
        "    latent = {\"samples\": torch.ones([1, 16, 1024 // 8, 1024 // 8]) * 0.0609}\n",
        "    prompt= \"a female character with long, flowing hair that appears to be made of ethereal, swirling patterns resembling the Northern Lights or Aurora Borealis. The background is dominated by deep blues and purples, creating a mysterious and dramatic atmosphere. The character's face is serene, with pale skin and striking features. She wears a dark-colored outfit with subtle patterns. The overall style of the artwork is reminiscent of fantasy or supernatural genres\"\n",
        "    cond, pooled = clip.encode_from_tokens(clip.tokenize(prompt), return_pooled=True)\n",
        "    cond = [[cond, {\"pooled_output\": pooled}]]\n",
        "    negative_prompt = \"bad quality, poor quality, doll, disfigured, jpg, toy, bad anatomy, missing limbs, missing fingers, 3d, cgi\"\n",
        "    n_cond, n_pooled = clip.encode_from_tokens(clip.tokenize(negative_prompt), return_pooled=True)\n",
        "    n_cond = [[n_cond, {\"pooled_output\": n_pooled}]]\n",
        "\n",
        "    n_cond1 = node_helpers.conditioning_set_values(n_cond, {\"start_percent\": 0, \"end_percent\": 0.1})\n",
        "    n_cond2 = zero_out(n_cond)\n",
        "    n_cond2 = node_helpers.conditioning_set_values(n_cond2[0], {\"start_percent\": 0.1, \"end_percent\": 1.0})\n",
        "    n_cond = n_cond1 + n_cond2\n",
        "\n",
        "    seed = 1\n",
        "    if seed == 0:\n",
        "        seed = random.randint(0, 18446744073709551615)\n",
        "    print(seed)\n",
        "    sample = nodes.common_ksampler(model=model_patcher, \n",
        "                            seed=seed, \n",
        "                            steps=28, \n",
        "                            cfg=4.5, \n",
        "                            sampler_name=\"dpmpp_2m\", \n",
        "                            scheduler=\"sgm_uniform\", \n",
        "                            positive=cond, \n",
        "                            negative=n_cond,\n",
        "                            latent=latent, \n",
        "                            denoise=1)\n",
        "    sample = sample[0][\"samples\"].to(torch.float16)\n",
        "    vae.first_stage_model.cuda()\n",
        "    decoded = vae.decode_tiled(sample).detach()\n",
        "\n",
        "Image.fromarray(np.array(decoded*255, dtype=np.uint8)[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
